#!/usr/bin/env python3
"""
×—×™×©×•×‘ ×˜×•×§× ×™× ×œ×›×œ ×©××œ×” ×-20 ×”×©××œ×•×ª - ×¢× tiktoken (××“×•×™×§)
"""
import sys
import os
import json
sys.path.insert(0, os.getcwd())

try:
    import tiktoken
    USE_TIKTOKEN = True
    # OpenAI encoding (cl100k_base) - ××“×•×™×§ ×‘×™×•×ª×¨
    encoding = tiktoken.get_encoding("cl100k_base")
    print("âœ… ××©×ª××© ×‘-tiktoken (OpenAI encoding) ×œ×—×™×©×•×‘ ××“×•×™×§")
except ImportError:
    USE_TIKTOKEN = False
    print("âš ï¸  tiktoken ×œ× ××•×ª×§×Ÿ, ××©×ª××© ×‘×”×¢×¨×›×” ×’×¡×”")
    def estimate_tokens(text: str) -> int:
        """×”×¢×¨×›×ª ×˜×•×§× ×™× - ×‘×¢×‘×¨×™×ª ~1.3 ×˜×•×§× ×™× ×œ××™×œ×”"""
        words = len(text.split())
        return int(words * 1.3)

# ×§×¨×™××ª ×§×•×‘×¥ ×”×ª×•×¦××•×ª
with open('data/rag_questions_results.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# ×¤×•× ×§×¦×™×” ×œ×—×™×©×•×‘ ×˜×•×§× ×™×
def count_tokens(text: str) -> int:
    """×—×™×©×•×‘ ×˜×•×§× ×™× - ××“×•×™×§ ×¢× tiktoken ××• ×”×¢×¨×›×”"""
    if USE_TIKTOKEN:
        return len(encoding.encode(text))
    else:
        words = len(text.split())
        return int(words * 1.3)

# System prompt (××”×§×•×“ - ××œ×)
system_prompt = """××ª×” ××œ×•×•×” ×ª×”×œ×™×š ×©×œ ×©×™× ×•×™, ×¦××™×—×” ×•×™×¦×™×¨×ª ×‘×”×™×¨×•×ª ×¤× ×™××™×ª ×¢×‘×•×¨ ×œ×§×•×—×•×ª. 

×¢×œ×™×š ×œ×¢× ×•×ª ×¨×§ ×‘×¢×‘×¨×™×ª, ×‘×©×¤×” ×¤×©×•×˜×”, × ×§×™×™×” ×•×‘×¨×•×¨×” â€” ×›××• ×©×™×—×” ×× ×•×©×™×ª ×•×œ× ×›××• ××•×“×œ ×©×¤×”.

## ×¡×’× ×•×Ÿ ×”×“×™×‘×•×¨ ×©×œ×š:

- ×¨×’×•×¢, ××¦×™××•×ª×™, ××›×‘×“ ×•×××™×ª×™.

- ×œ×œ× ×“×¨××˜×™×•×ª ×•×œ×œ× ×§×œ×™×©××•×ª.

- ×ª×©×•×‘×•×ª ×§×¦×¨×•×ª ×××•×“, ××“×•×™×§×•×ª, ×•××‘×•×¡×¡×•×ª (5-8 ××©×¤×˜×™× ×‘×¡×š ×”×›×œ).

- ×˜×•×Ÿ ×× ×•×©×™: ×¢×“×™×Ÿ, ×—×©×•×£, ××‘×œ ×œ× "×¨×•×—× ×™-×™×ª×¨".

- × ×•×ª×Ÿ ××§×•× ×œ××” ×©×”×œ×§×•×— ××¨×’×™×©, ×œ× ××˜×™×£ ×•×œ× ×× ×¡×” ×œ×©×›× ×¢.

## ×›×œ×œ×™ ×¢×‘×•×“×”:

1. ××ª×” **×¢×•× ×” ×¨×§ ××ª×•×š ×”×¦'×× ×§×™× ×•×”×“×•×’×××•×ª** ×©×× ×™ ××¡×¤×§.  

   ××™×Ÿ ×œ×”××¦×™× ×™×“×¢, ××™×Ÿ ×œ×©×¢×¨, ×•××™×Ÿ ×œ×¢× ×•×ª ××¢×‘×¨ ×œ××” ×©×™×© ×‘×§×•× ×˜×§×¡×˜.

2. ×× ××™×Ÿ ××¡×¤×™×§ ××™×“×¢ ×›×“×™ ×œ×¢× ×•×ª â€” ××ª×” ××•××¨ ×–××ª ×‘×›× ×•×ª, ×‘×¦×•×¨×” ×¢×“×™× ×”:  

   "×œ× ××¦××ª×™ ×ª×©×•×‘×” ××“×•×™×§×ª ×‘×§×˜×¢×™× ×©×§×™×‘×œ×ª×™. ×× ×ª×¨×¦×”, ××•×›×œ ×œ×”×¦×™×¢ ×›×™×•×•×Ÿ ×›×œ×œ×™."

3. ×”×©×ª××© ×ª××™×“ ×‘×¢×™×‘×•×“ × ×›×•×Ÿ ×©×œ ×”×˜×§×¡×˜×™×:

   - ×ª×¡×›× ×‘××™×œ×™× ×©×œ×š, ××‘×œ ×ª×™×©××¨ × ×××Ÿ ×œ××©××¢×•×ª.

   - ××œ ×ª×¦×˜×˜ ×§×˜×¢×™× ××¨×•×›×™×.

   - ×ª×—×‘×¨ ×‘×™×Ÿ ×¨×¢×™×•× ×•×ª ×× ×¦×¨×™×š, ××‘×œ ×œ× ×ª×‘× ×” ×ª××•×¨×™×” ×—×“×©×”.

4. ×ª××™×“ ×ª×¢× ×” ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª:

   - ××©×¤×˜×™× ×§×¦×¨×™×.

   - ×œ×œ× ×× ×’×œ×™×ª (×—×•×¥ ×××•× ×—×™× ×˜×›× ×™×™× ×›×©×—×™×™×‘×™×).

   - ×œ×œ× ×¡××œ×™×/××™××•×’'×™×.

## ××‘× ×” ×ª×©×•×‘×” ××•××œ×¥ (×—×©×•×‘ ×××•×“ - ×ª×©×•×‘×” ×§×¦×¨×”!):

- ××©×¤×˜ ×¤×ª×™×—×” ×©××–×”×” ××ª ×”×›×•×•× ×” ×©×œ ×”××“× (1-2 ××©×¤×˜×™×).

- ×”×¡×‘×¨ ×§×¦×¨ ××ª×•×š ×”×§×•× ×˜×§×¡×˜ (2-3 ××©×¤×˜×™× ×‘×œ×‘×“).

- ××©×¤×˜ ×©××—×‘×¨ ××ª ×–×” ×œ×—×•×•×™×” ×”×™×•××™×•××™×ª ×©×œ×• (1 ××©×¤×˜).

- ×× ××ª××™×: ×”×¦×¢×” ×§×˜× ×” ×•×¤×¨×§×˜×™×ª ×œ×”××©×š (1 ××©×¤×˜).

- ×¡×™×•× ×¤×ª×•×—: "×× ×ª×¨×¦×” × ×¢××™×§ ×‘×–×”."

**×—×©×•×‘: ×”×ª×©×•×‘×” ×¦×¨×™×›×” ×œ×”×™×•×ª ×§×¦×¨×” - 5-8 ××©×¤×˜×™× ×‘×¡×š ×”×›×œ. ×œ× ×™×•×ª×¨.**

## ×”×ª×™×™×—×¡×•×ª ×œ×©××œ×•×ª ×§×¦×¨×•×ª, ×¤×ª×™×—×•×ª ×•×¡××•×œÖ¾×˜×•×§:

×× ×”××©×ª××© ×›×•×ª×‘ ××™×œ×™× ×›×œ×œ×™×•×ª ×›××•:

"×©×œ×•×", "×”×™×™", "××” ×§×•×¨×”", "××” × ×©××¢", "××” ×§×•×¨×”?", "××” ×”××¦×‘", ××• ×›×œ ×¤× ×™×™×” ×©××™× ×” ×‘×××ª ×©××œ×” ××”×•×ª×™×ª â€”

×¢×œ×™×š ×œ×¢× ×•×ª ×‘×§×¦×¨×” ×××•×“, ×‘× ×™××•×¡ ×•×‘×¤×©×˜×•×ª, ×‘×œ×™ ×œ×”×¤×¢×™×œ RAG ×•×‘×œ×™ × ×™×ª×•×— ×¨×’×©×™.

**×—×©×•×‘ ×××•×“: ×©××œ×•×ª ×›××œ×” ××§×‘×œ×•×ª ×ª×©×•×‘×” ×©×œ 1-2 ××©×¤×˜×™× ×‘×œ×‘×“. ×œ× ×™×•×ª×¨.**

×“×•×’×××•×ª:

- "×©×œ×•×!" â†’ "×”×™×™, ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"

- "××” × ×©××¢?" â†’ "×‘×¡×“×¨, ×ª×•×“×”! ××™×š ××¤×©×¨ ×œ×¡×™×™×¢ ×œ×š?"

- "××” ×§×•×¨×”?" â†’ "×‘×¡×“×¨, ×ª×•×“×”! ××” ×ª×¨×¦×” ×œ×©××•×œ?"

- "×”×™×™" â†’ "×”×™×™, ××” ×ª×¨×¦×” ×œ×©××•×œ?"

- "××” ×”××¦×‘?" â†’ "×‘×¡×“×¨, ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"

**××™×Ÿ ×œ×¢× ×•×ª ×‘×ª×•×›×Ÿ ×¢×•××§, ××™×Ÿ ×œ×¤×¨×© ×–××ª ×›×”×–×× ×” ×œ× ×™×ª×•×—, ×•××™×Ÿ ×œ×©×œ×•×£ ×§×•× ×˜×§×¡×˜.**

**××™×Ÿ ×œ×”×©×ª××© ×‘×§×˜×¢×™× ××”×§×•× ×˜×§×¡×˜, ××™×Ÿ ×œ× ×ª×— ×¨×’×©×™×ª, ×•××™×Ÿ ×œ×ª×ª ×”×¡×‘×¨×™× ××¨×•×›×™×.**

×¨×§ ×ª×©×•×‘×ª ×¤×ª×™×—×” ×× ×•××¡×ª, ×× ×•×©×™×ª ×•×§×¦×¨×” ×××•×“ (1-2 ××©×¤×˜×™×).

×–×” ×›×œ ××” ×©××ª×” ×¦×¨×™×š ×œ×¢×©×•×ª. 

×ª××™×“ ×œ×¢× ×•×ª ×‘×¢×‘×¨×™×ª. 

×ª××™×“ ××‘×•×¡×¡ ×§×•× ×˜×§×¡×˜ (××œ× ×× ×–×• ×©××œ×” ×§×¦×¨×”/×¤×ª×™×—×”).

×ª××™×“ ×‘×¡×’× ×•×Ÿ ×× ×•×©×™ ×•×¦×œ×•×œ."""

# Few-shot section (×”×¢×¨×›×” - ×‘×“×¨×š ×›×œ×œ ×§×¦×¨)
few_shot_section = "\n\n×“×•×’×××•×ª ×œ×¡×’× ×•×Ÿ ×”×ª×©×•×‘×” (××ª×•×š FAQ ×©×œ ×˜×œ ×‘×©×Ÿ):\n[×“×•×’×××•×ª ×§×¦×¨×•×ª]\n\n---\n"

# ×—×™×©×•×‘ ×œ×›×œ ×©××œ×”
results = []
total_prompt_tokens = 0
total_context_tokens = 0
total_question_tokens = 0

print("=" * 80)
print("ğŸ“Š ×—×™×©×•×‘ ×˜×•×§× ×™× ×œ×›×œ ×©××œ×” ×-20 ×”×©××œ×•×ª")
print("=" * 80)

for i, result in enumerate(data['results'], 1):
    question = result['question']
    
    # ×‘× ×™×™×ª context ××ª×•×š chunks
    context_parts = []
    total_context_length = 0
    max_context = 1200  # ×›××• ×‘×§×•×“
    
    for chunk in result['chunks']:
        chunk_text = chunk['text']
        if total_context_length + len(chunk_text) > max_context:
            remaining = max_context - total_context_length
            if remaining > 100:
                chunk_text = chunk_text[:remaining] + "..."
            else:
                break
        context_parts.append(f"[××§×•×¨ {len(context_parts)+1}] {chunk['source']}:\n{chunk_text}")
        total_context_length += len(chunk_text)
    
    context_text = "\n\n".join(context_parts)
    
    # ×—×™×©×•×‘ ×˜×•×§× ×™×
    system_tokens = count_tokens(system_prompt)
    few_shot_tokens = count_tokens(few_shot_section)
    context_tokens = count_tokens(context_text)
    question_tokens = count_tokens(question)
    
    # ×—×™×©×•×‘ overhead - [INST] tags ×•×›×•'
    inst_tags = "[INST] [/INST]"
    prompt_overhead = count_tokens(inst_tags) + 10  # +10 ×¢×‘×•×¨ formatting
    
    total_prompt_tokens_for_q = system_tokens + few_shot_tokens + context_tokens + question_tokens + prompt_overhead
    
    total_prompt_tokens += total_prompt_tokens_for_q
    total_context_tokens += context_tokens
    total_question_tokens += question_tokens
    
    results.append({
        "question_num": i,
        "question": question[:60] + "..." if len(question) > 60 else question,
        "system_tokens": system_tokens,
        "few_shot_tokens": few_shot_tokens,
        "context_tokens": context_tokens,
        "question_tokens": question_tokens,
        "overhead_tokens": prompt_overhead,
        "total_prompt_tokens": total_prompt_tokens_for_q,
        "context_length": total_context_length,
        "num_chunks": len(result['chunks'])
    })
    
    print(f"\n[{i:2d}] {question[:50]}...")
    print(f"     System: {system_tokens:4d} | Few-shot: {few_shot_tokens:3d} | Context: {context_tokens:4d} | Question: {question_tokens:3d} | Overhead: {prompt_overhead:2d}")
    print(f"     ğŸ“Š ×¡×”\"×› Prompt: {total_prompt_tokens_for_q:4d} ×˜×•×§× ×™× | Context: {total_context_length:4d} ×ª×•×•×™× | Chunks: {len(result['chunks'])}")

# ×¡×™×›×•×
print("\n" + "=" * 80)
print("ğŸ“Š ×¡×™×›×•× ×›×œ×œ×™")
print("=" * 80)
print(f"\nâœ… ×¡×”\"×› ×©××œ×•×ª: {len(results)}")
print(f"ğŸ“ˆ ×××•×¦×¢ ×˜×•×§× ×™× ×œ×©××œ×”: {total_prompt_tokens // len(results):.0f}")
print(f"ğŸ“ˆ ×××•×¦×¢ context ×˜×•×§× ×™×: {total_context_tokens // len(results):.0f}")
print(f"ğŸ“ˆ ×××•×¦×¢ question ×˜×•×§× ×™×: {total_question_tokens // len(results):.0f}")

print(f"\nğŸ“Š ×”×ª×¤×œ×’×•×ª:")
min_tokens = min(r['total_prompt_tokens'] for r in results)
max_tokens = max(r['total_prompt_tokens'] for r in results)
avg_tokens = total_prompt_tokens // len(results)

print(f"   ××™× ×™××•×: {min_tokens} ×˜×•×§× ×™×")
print(f"   ××§×¡×™××•×: {max_tokens} ×˜×•×§× ×™×")
print(f"   ×××•×¦×¢: {avg_tokens} ×˜×•×§× ×™×")

# ×©××œ×•×ª ×¢× ×”×›×™ ×”×¨×‘×”/×§×¦×ª ×˜×•×§× ×™×
sorted_results = sorted(results, key=lambda x: x['total_prompt_tokens'])
print(f"\nğŸ” 3 ×©××œ×•×ª ×¢× ×”×›×™ ×”×¨×‘×” ×˜×•×§× ×™×:")
for r in sorted_results[-3:]:
    print(f"   [{r['question_num']:2d}] {r['total_prompt_tokens']:4d} ×˜×•×§× ×™× - {r['question']}")

print(f"\nğŸ”» 3 ×©××œ×•×ª ×¢× ×”×›×™ ××¢×˜ ×˜×•×§× ×™×:")
for r in sorted_results[:3]:
    print(f"   [{r['question_num']:2d}] {r['total_prompt_tokens']:4d} ×˜×•×§× ×™× - {r['question']}")

print(f"\nğŸ’¡ ×”×¢×¨×”: ×–×” ×”×¢×¨×›×” ×’×¡×” (~1.3 ×˜×•×§× ×™× ×œ××™×œ×” ×‘×¢×‘×¨×™×ª)")
print(f"   Context window ×©×œ Dicta-LM 2.0: 2048 ×˜×•×§× ×™×")
print(f"   ×›×œ ×”×©××œ×•×ª × ×›× ×¡×•×ª ×‘-context window! âœ…")

