#!/usr/bin/env python3
"""
Optimize the vector index for better performance
"""
import psycopg2
import os

DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://tzahimoyal@localhost:5432/talbashanai")

def optimize_index():
    """Rebuild the vector index with optimal parameters"""
    conn = psycopg2.connect(DATABASE_URL)
    cursor = conn.cursor()
    
    try:
        # Get table size
        cursor.execute('SELECT COUNT(*) FROM knowledge_chunks')
        count = cursor.fetchone()[0]
        print(f"ğŸ“Š ××¡×¤×¨ chunks ×‘×˜×‘×œ×”: {count}")
        
        # Calculate optimal lists parameter
        # For ivfflat: lists should be rows / 1000 (minimum 10)
        optimal_lists = max(10, count // 1000)
        print(f"ğŸ’¡ lists ××•××œ×¥: {optimal_lists}")
        
        # Check current index
        cursor.execute('''
            SELECT indexname, indexdef
            FROM pg_indexes 
            WHERE tablename = 'knowledge_chunks' AND indexname LIKE '%embedding%'
        ''')
        current = cursor.fetchone()
        
        if current:
            print(f"\nğŸ“Š ××™× ×“×§×¡ × ×•×›×—×™: {current[0]}")
            if 'lists=' in current[1]:
                current_lists = int(current[1].split('lists=')[1].split(')')[0].strip("'"))
                print(f"   lists × ×•×›×—×™: {current_lists}")
                
                if current_lists < optimal_lists:
                    print(f"\nâš ï¸  ×”××™× ×“×§×¡ ×œ× ××•×ª××! ×‘×•× ×” ××—×“×© ×¢× lists={optimal_lists}...")
                    
                    # Drop old index
                    cursor.execute('DROP INDEX IF EXISTS knowledge_chunks_embedding_idx')
                    conn.commit()
                    print("âœ… ××™× ×“×§×¡ ×™×©×Ÿ × ××—×§")
                    
                    # Create new index with optimal parameters
                    cursor.execute(f'''
                        CREATE INDEX knowledge_chunks_embedding_idx 
                        ON knowledge_chunks 
                        USING ivfflat (embedding vector_cosine_ops) 
                        WITH (lists={optimal_lists})
                    ''')
                    conn.commit()
                    print(f"âœ… ××™× ×“×§×¡ ×—×“×© × ×•×¦×¨ ×¢× lists={optimal_lists}")
                else:
                    print("âœ… ×”××™× ×“×§×¡ ×›×‘×¨ ××•×ª××")
            else:
                print("âš ï¸  ×œ× × ××¦× lists parameter - ×‘×•× ×” ××™× ×“×§×¡ ×—×“×©...")
                cursor.execute('DROP INDEX IF EXISTS knowledge_chunks_embedding_idx')
                cursor.execute(f'''
                    CREATE INDEX knowledge_chunks_embedding_idx 
                    ON knowledge_chunks 
                    USING ivfflat (embedding vector_cosine_ops) 
                    WITH (lists={optimal_lists})
                ''')
                conn.commit()
                print(f"âœ… ××™× ×“×§×¡ ×—×“×© × ×•×¦×¨")
        else:
            print("âš ï¸  ×œ× × ××¦× ××™× ×“×§×¡ - ×™×•×¦×¨ ×—×“×©...")
            cursor.execute(f'''
                CREATE INDEX knowledge_chunks_embedding_idx 
                ON knowledge_chunks 
                USING ivfflat (embedding vector_cosine_ops) 
                WITH (lists={optimal_lists})
            ''')
            conn.commit()
            print(f"âœ… ××™× ×“×§×¡ × ×•×¦×¨")
        
        # Analyze table for better query planning
        print("\nğŸ“Š ××¨×™×¥ ANALYZE ×¢×œ ×”×˜×‘×œ×”...")
        cursor.execute('ANALYZE knowledge_chunks')
        conn.commit()
        print("âœ… ANALYZE ×”×•×©×œ×")
        
    except Exception as e:
        print(f"âŒ ×©×’×™××”: {e}")
        conn.rollback()
    finally:
        cursor.close()
        conn.close()

if __name__ == "__main__":
    print("ğŸš€ ××•×¤×˜×™××™×–×¦×™×” ×©×œ ××™× ×“×§×¡ ×”-vector")
    print("=" * 80)
    optimize_index()
    print("=" * 80)
    print("âœ… ×¡×™×•×!")

