// Full flow test - from question to OpenAI response
import { config } from 'dotenv'
import { resolve } from 'path'

// Load .env file
config({ path: resolve(process.cwd(), '.env') })

import { queryWithOpenAIRag } from '../src/server/vector/queryWithOpenAIRag'

async function testFullFlow() {
  console.log('ğŸ§ª ×‘×“×™×§×” ××œ××” ×©×œ ×”-flow ×¢× OpenAI\n')
  console.log('='.repeat(100))
  
  // Step 1: Check environment
  console.log('\n1ï¸âƒ£ ×‘×“×™×§×ª ××©×ª× ×™ ×¡×‘×™×‘×”:')
  const useOpenAI = process.env.USE_OPENAI === 'true'
  const hasApiKey = !!process.env.OPENAI_API_KEY
  const model = process.env.OPENAI_MODEL || 'gpt-4o-mini'
  const embeddingModel = process.env.OPENAI_EMBEDDING_MODEL || 'text-embedding-3-small'
  
  console.log(`   USE_OPENAI: ${useOpenAI ? 'âœ…' : 'âŒ'}`)
  console.log(`   OPENAI_API_KEY: ${hasApiKey ? 'âœ… ×§×™×™×' : 'âŒ ×—×¡×¨'}`)
  console.log(`   OPENAI_MODEL: ${model}`)
  console.log(`   OPENAI_EMBEDDING_MODEL: ${embeddingModel}`)
  
  if (!useOpenAI || !hasApiKey) {
    console.log('\nâŒ ××©×ª× ×™ ×¡×‘×™×‘×” ×œ× ××•×’×“×¨×™× × ×›×•×Ÿ!')
    console.log('   ×•×“× ×©-USE_OPENAI=true ×•-OPENAI_API_KEY ××•×’×“×¨ ×‘-.env')
    process.exit(1)
  }
  
  // Step 2: Test OpenAI API directly
  console.log('\n2ï¸âƒ£ ×‘×•×“×§ ×—×™×‘×•×¨ ×œ-OpenAI API...')
  try {
    const { chatCompletion } = await import('../src/server/openai')
    const testResponse = await chatCompletion([
      {
        role: 'user',
        content: 'Say "Hello" in Hebrew'
      }
    ], {
      temperature: 0.3,
      maxTokens: 50
    })
    
    if (testResponse.choices[0]?.message?.content) {
      console.log(`   âœ… OpenAI API ×¢×•×‘×“!`)
      console.log(`   ×ª×©×•×‘×”: ${testResponse.choices[0].message.content}`)
    } else {
      console.log('   âŒ OpenAI API ×œ× ×”×—×–×™×¨ ×ª×©×•×‘×”')
      process.exit(1)
    }
  } catch (error: any) {
    console.error('   âŒ ×©×’×™××” ×‘×—×™×‘×•×¨ ×œ-OpenAI API:')
    console.error(`   ${error.message}`)
    process.exit(1)
  }
  
  // Step 3: Test OpenAI Embeddings
  console.log('\n3ï¸âƒ£ ×‘×•×“×§ OpenAI Embeddings...')
  try {
    const { embedText } = await import('../src/server/openai')
    const embedding = await embedText('test query')
    
    if (embedding && embedding.length > 0) {
      console.log(`   âœ… OpenAI Embeddings ×¢×•×‘×“!`)
      console.log(`   ××™××“×™×: ${embedding.length}`)
    } else {
      console.log('   âŒ OpenAI Embeddings ×œ× ×”×—×–×™×¨ ×•×§×˜×•×¨')
      process.exit(1)
    }
  } catch (error: any) {
    console.error('   âŒ ×©×’×™××” ×‘-OpenAI Embeddings:')
    console.error(`   ${error.message}`)
    process.exit(1)
  }
  
  // Step 4: Test RAG retrieval + OpenAI
  console.log('\n4ï¸âƒ£ ×‘×•×“×§ RAG + OpenAI (×”×©××œ×” ×”××œ××”)...')
  const testQuestion = '××” ×–×” ×¨×™××§×˜×™×‘×™×•×ª?'
  
  try {
    console.log(`\nğŸ“ ×©××œ×”: "${testQuestion}"`)
    console.log('   ××—×¤×© ×¦\'×× ×§×™×...')
    
    const startTime = Date.now()
    const result = await queryWithOpenAIRag(
      testQuestion,
      testQuestion,
      50, // topK
      8,  // topN
      undefined // userContext
    )
    const totalTime = (Date.now() - startTime) / 1000
    
    console.log(`\nâœ… ×”×¦×œ×—×”!`)
    console.log(`   ×–××Ÿ ×›×•×œ×œ: ${totalTime.toFixed(2)} ×©× ×™×•×ª`)
    console.log(`   ×¦'×× ×§×™× × ××¦××•: ${result.sources.length}`)
    
    if (result.timing) {
      console.log(`\nâ±ï¸  Timing:`)
      console.log(`   Retrieve: ${result.timing.retrieve_time?.toFixed(2)}s`)
      console.log(`   LLM: ${result.timing.llm_time?.toFixed(2)}s`)
      console.log(`   Total: ${result.timing.total_time?.toFixed(2)}s`)
    }
    
    if (result.answer && result.answer.length > 0) {
      console.log(`\nğŸ“ ×ª×©×•×‘×” ×-OpenAI (${result.answer.length} ×ª×•×•×™×):`)
      console.log('-'.repeat(100))
      console.log(result.answer.substring(0, 500))
      if (result.answer.length > 500) {
        console.log('...')
      }
      console.log('-'.repeat(100))
      
      console.log(`\nâœ… ×”××¢×¨×›×ª ×¢×•×‘×“×ª!`)
      console.log(`   - Python RAG retrieval: âœ…`)
      console.log(`   - OpenAI API: âœ…`)
      console.log(`   - ×ª×©×•×‘×” ×”×ª×§×‘×œ×”: âœ…`)
    } else {
      console.log('\nâŒ ×”×ª×©×•×‘×” ×¨×™×§×”!')
      process.exit(1)
    }
    
    // Show sources
    if (result.sources.length > 0) {
      console.log(`\nğŸ“š ×¦'×× ×§×™× ×©× ××¦××• (${result.sources.length}):`)
      result.sources.slice(0, 3).forEach((chunk, idx) => {
        console.log(`\n   [${idx + 1}] ${chunk.source}`)
        console.log(`       Score: ${chunk.rerank_score.toFixed(3)}`)
        console.log(`       Text: ${chunk.text.substring(0, 100)}...`)
      })
    } else {
      console.log('\nâš ï¸  ×œ× × ××¦××• ×¦\'×× ×§×™× - ×™×™×ª×›×Ÿ ×©×”××™× ×“×§×¡ ×¨×™×§')
    }
    
  } catch (error) {
    console.error('\nâŒ ×©×’×™××” ×‘×‘×“×™×§×”:')
    console.error(error)
    if (error instanceof Error) {
      console.error(`   Message: ${error.message}`)
      if (error.stack) {
        console.error(`   Stack: ${error.stack.substring(0, 500)}...`)
      }
    }
    process.exit(1)
  }
  
  console.log('\n' + '='.repeat(100))
  console.log('âœ… ×‘×“×™×§×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”! ×”××¢×¨×›×ª ×¢×•×‘×“×ª ×¢× OpenAI.')
  console.log('='.repeat(100))
}

testFullFlow().catch(console.error)
