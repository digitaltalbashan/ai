// Script to improve metadata for ALL chunks in database
import { prisma } from '../src/server/db/client'

/**
 * Estimate tokens
 */
function estimateTokens(text: string): number {
  return Math.ceil(text.length / 4)
}

/**
 * Analyze and improve chunk metadata
 */
function improveMetadata(chunk: { id: string; text: string; metadata: any; source: string | null }): any {
  const text = chunk.text.toLowerCase()
  const words = chunk.text.split(/\s+/).filter(Boolean)
  const metadata = chunk.metadata || {}
  
  // Determine chunk type
  let chunkType: 'intro' | 'content' | 'summary' | 'general' = 'content'
  
  const introIndicators = ['◊©◊ú◊ï◊ù', '◊ë◊®◊ï◊õ◊ô◊ù', '◊†◊™◊ó◊ô◊ú', '◊î◊ô◊ï◊ù', '◊ë◊©◊ô◊¢◊ï◊®', '◊ë◊§◊®◊ß', '◊ê◊†◊ó◊†◊ï']
  const summaryIndicators = ['◊°◊ô◊õ◊ï◊ù', '◊ú◊°◊ô◊õ◊ï◊ù', '◊ë◊°◊ï◊£', '◊ú◊°◊ô◊ï◊ù', '◊ú◊õ◊ü', '◊ú◊°◊ô◊õ◊ï◊ù', '◊ú◊°◊ô◊õ◊ï◊ù']
  
  if (introIndicators.some(ind => text.includes(ind)) && text.length < 500) {
    chunkType = 'intro'
  } else if (summaryIndicators.some(ind => text.includes(ind))) {
    chunkType = 'summary'
  } else {
    // Check if chunk is too general
    const commonWords = ['◊ñ◊î', '◊©◊ú', '◊ê◊™', '◊¢◊ú', '◊ê◊ï', '◊ê◊ù', '◊õ◊ô', '◊ê◊ñ', '◊í◊ù', '◊ô◊ï◊™◊®', '◊ê◊†◊ó◊†◊ï', '◊ê◊†◊ô']
    const commonWordCount = words.filter(w => commonWords.includes(w.toLowerCase())).length
    if (commonWordCount > words.length * 0.35) {
      chunkType = 'general'
    }
  }
  
  // Extract topic (first meaningful sentence)
  const sentences = chunk.text.split(/[.!?]\s+/).filter(s => s.length > 20)
  let topic = metadata.topic || ''
  if (!topic && sentences.length > 0) {
    topic = sentences[0].substring(0, 100).trim()
    if (topic.length < 30 && sentences.length > 1) {
      topic = sentences[1].substring(0, 100).trim()
    }
  }
  
  // Extract key concepts
  const courseConcepts = [
    '◊û◊¢◊í◊ú ◊î◊™◊ï◊ì◊¢◊î', '◊™◊ï◊ì◊¢◊î ◊®◊ê◊ß◊ò◊ô◊ë◊ô◊™', '◊™◊ï◊ì◊¢◊î ◊ê◊ß◊ò◊ô◊ë◊ô◊™', '◊™◊ï◊ì◊¢◊î ◊ô◊¶◊ô◊®◊™◊ô◊™',
    '◊™◊™ ◊û◊ï◊ì◊¢', '◊®◊¶◊ï◊ü ◊ó◊ï◊§◊©◊ô', '◊§◊ó◊ì', '◊û◊¶◊ô◊ê◊ï◊™', '◊©◊ó◊ô◊ß◊î', '◊™◊ß◊ô◊¢◊ï◊™',
    '◊™◊ï◊ì◊¢◊î', '◊û◊†◊î◊ô◊í◊ï◊™ ◊™◊ï◊ì◊¢◊™◊ô◊™', '◊™◊ô◊ß◊ï◊ü', '◊î◊®◊í◊ú', '◊î◊™◊†◊í◊ì◊ï◊™',
    '◊ß◊ï◊†◊§◊ú◊ô◊ß◊ò', '◊¶◊û◊ô◊ó◊î', '◊§◊ô◊™◊ï◊ó ◊ê◊ô◊©◊ô', '◊û◊†◊î◊ô◊í◊ï◊™',
    'R', 'A', 'C', '◊™◊ï◊ì◊¢◊™ R', '◊™◊ï◊ì◊¢◊™ A', '◊™◊ï◊ì◊¢◊™ C'
  ]
  
  const keyConcepts: string[] = metadata.key_concepts || []
  for (const concept of courseConcepts) {
    if (text.includes(concept.toLowerCase()) && !keyConcepts.includes(concept)) {
      keyConcepts.push(concept)
      if (keyConcepts.length >= 5) break
    }
  }
  
  return {
    ...metadata,
    topic: topic || metadata.topic,
    key_concepts: keyConcepts.length > 0 ? keyConcepts : metadata.key_concepts,
    word_count: words.length,
    token_count: estimateTokens(chunk.text),
    is_standalone: words.length > 100 && estimateTokens(chunk.text) > 50,
    chunk_type: chunkType,
    is_general: chunkType === 'general',
    updated_at: new Date().toISOString()
  }
}

async function main() {
  console.log('üîç Improving metadata for ALL chunks...')
  console.log('='.repeat(80))
  
  // Get total count
  const totalCount = await prisma.$queryRawUnsafe<Array<{ count: bigint }>>(
    `SELECT COUNT(*) as count FROM knowledge_chunks`
  )
  const total = Number(totalCount[0].count)
  
  console.log(`\nüìä Total chunks: ${total}`)
  console.log(`\nüíæ Processing chunks...`)
  
  let processed = 0
  let updated = 0
  let errors = 0
  const batchSize = 100
  
  // Process in batches
  let offset = 0
  
  while (offset < total) {
    const chunks = await prisma.$queryRawUnsafe<any[]>(
      `SELECT id, text, metadata, source 
       FROM knowledge_chunks 
       ORDER BY id 
       LIMIT $1 OFFSET $2`,
      batchSize,
      offset
    )
    
    if (chunks.length === 0) break
    
    for (const chunk of chunks) {
      try {
        const improvedMetadata = improveMetadata(chunk)
        
        await prisma.$executeRawUnsafe(
          `UPDATE knowledge_chunks 
           SET metadata = $1::jsonb
           WHERE id = $2`,
          JSON.stringify(improvedMetadata),
          chunk.id
        )
        
        updated++
        processed++
        
        if (processed % 500 === 0) {
          console.log(`   Progress: ${processed}/${total} (${(processed / total * 100).toFixed(1)}%)`)
        }
      } catch (error) {
        errors++
        if (errors <= 5) {
          console.error(`   ‚ùå Error updating ${chunk.id}:`, error)
        }
      }
    }
    
    offset += batchSize
  }
  
  console.log(`\n` + '='.repeat(80))
  console.log('‚ú® Metadata improvement complete!')
  console.log('='.repeat(80))
  console.log(`‚úÖ Processed: ${processed}`)
  console.log(`‚úÖ Updated: ${updated}`)
  console.log(`‚ùå Errors: ${errors}`)
  console.log('='.repeat(80))
  
  await prisma.$disconnect()
}

main().catch(console.error)

