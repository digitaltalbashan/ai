# 🧠 מנגנון הזיכרון - הסבר מפורט

## סקירה כללית

המערכת משתמשת בשני סוגי זיכרונות שמשלימים זה את זה:

1. **זיכרון פעיל (ACTIVE_CONVERSATION)** - זיכרון קצר טווח של השיחה הנוכחית
2. **זיכרון מתמשך (Long-term Memory)** - זיכרון ארוך טווח של עובדות, העדפות ונושאים

---

## 📋 1. זיכרון פעיל (ACTIVE_CONVERSATION)

### מה זה?
זיכרון שמתעדכן **בכל הודעה** ומכיל סיכום של כל מה שנאמר בשיחה הפעילה.

### איפה נשמר?
- **טבלה**: `user_memories`
- **סוג**: `ACTIVE_CONVERSATION`
- **מבנה**: זיכרון אחד למשתמש (unique constraint על `userId + memoryType`)

### איך זה עובד?

#### שלב 1: עדכון הזיכרון (אחרי כל הודעה)
```typescript
// אחרי שהמשתמש שולח הודעה והעוזר עונה:

1. איסוף כל ההודעות מהשיחה:
   const allMessages = await prisma.message.findMany({
     where: { conversationId: conversation.id },
     orderBy: { createdAt: 'asc' }
   })

2. יצירת סיכום עם LLM:
   - שולח את כל ההודעות ל-LLM
   - מבקש סיכום תמציתי בעברית (2-4 משפטים)
   - הסיכום כולל:
     * מה המשתמש שאל
     * מה העוזר הסביר
     * נושאים מרכזיים שנדונו
     * פרטי קונטקסט חשובים

3. יצירת embedding לסיכום:
   - משתמש ב-text-embedding-3-small (1536 dimensions)
   - שומר את ה-embedding למטרות חיפוש עתידיות

4. שמירה במסד הנתונים:
   - UPSERT: מעדכן זיכרון קיים או יוצר חדש
   - תמיד יש רק זיכרון אחד מסוג ACTIVE_CONVERSATION למשתמש
```

#### שלב 2: טעינת הזיכרון (לפני כל תשובה)
```typescript
// לפני יצירת תשובה:

1. חיפוש זיכרון פעיל:
   const memories = await searchUserMemories(userId, question, 1)
   const activeMemory = memories.find(m => m.memoryType === 'ACTIVE_CONVERSATION')

2. הוספה לפרומפט:
   - הזיכרון נשלף מה-DB (עם embedding search)
   - מתווסף ל-system prompt
   - מופיע לפני ההודעות האחרונות
```

### דוגמה לסיכום זיכרון פעיל:
```
"המשתמש שאל על מהות התודעה הריאקטיבית. הסברתי שהתודעה הריאקטיבית 
מתייחסת לתגובות אוטומטיות או בלתי מודעות של האדם לסיטואציות שונות, 
ולעיתים היא נובעת מהתניות עבר. הנושאים המרכזיים שנדונו כוללים את 
ההבדל בין תודעה ריאקטיבית לתודעה מודעת."
```

---

## 🗂️ 2. זיכרון מתמשך (Long-term Memory)

### מה זה?
זיכרון שמכיל **עובדות, העדפות ונושאים מתמשכים** על המשתמש שחיים מחוץ לשיחה הספציפית.

### איפה נשמר?
- **טבלה**: `user_contexts`
- **פורמט**: JSON structure
- **מבנה**: זיכרון אחד למשתמש (unique על `userId`)

### מבנה הזיכרון:
```json
{
  "user_id": "123",
  "profile": {
    "name": "עומר",
    "location": "תל אביב",
    "lang": "he"
  },
  "preferences": [
    "מעדיף תשובות בעברית",
    "מתעניין בארכיטקטורת backend"
  ],
  "long_term_facts": [
    {
      "id": "job",
      "text": "המשתמש עובד כמפתח backend.",
      "importance": "high",
      "last_updated": "2025-11-28T10:00:00Z",
      "last_used": "2025-11-28T10:00:00Z"
    }
  ],
  "conversation_themes": [
    "ניהול קונטקסט LLM",
    "עיצוב שכבת זיכרון"
  ],
  "memory_summary": "סיכום תמציתי של כל הזיכרון",
  "last_updated": "2025-11-28T10:00:00Z"
}
```

### איך זה עובד?

#### שלב 1: טעינת הזיכרון (לפני כל תשובה)
```typescript
// לפני יצירת תשובה:

1. טעינת הזיכרון מהמסד:
   const longTermMemory = await loadLongTermMemory(userId)

2. יצירת snippet תמציתי:
   const memorySnippet = buildMemorySnippet(longTermMemory, 500)
   // כולל רק:
   // - פרופיל (אם קיים)
   // - העדפות
   // - עובדות חשובות (importance: high)
   // - סיכום זיכרון

3. הוספה לפרומפט:
   - ה-snippet מתווסף ל-system prompt
   - מופיע לפני ה-RAG chunks ו-active memory
```

#### שלב 2: עדכון הזיכרון (אחרי כל תשובה)
```typescript
// אחרי שהעוזר עונה:

1. שליחה ל-LLM כ-Memory Extractor:
   - שולח את הזיכרון הנוכחי (JSON)
   - שולח את הודעת המשתמש
   - שולח את תשובת העוזר
   - מבקש מה-LLM לעדכן את ה-JSON

2. LLM מחזיר JSON מעודכן:
   - מוסיף עובדות חדשות
   - מעדכן עובדות קיימות
   - מוחק עובדות מיושנות/סותרות
   - מעדכן העדפות ונושאים

3. שמירה במסד הנתונים:
   await saveLongTermMemory(userId, updatedMemory)
```

### דוגמה לעדכון:
```typescript
// לפני:
{
  "preferences": ["מעדיף תשובות בעברית"]
}

// אחרי שהמשתמש אמר: "אני אוהב דוגמאות קוד קצרות"
// LLM מעדכן:
{
  "preferences": [
    "מעדיף תשובות בעברית",
    "אוהב דוגמאות קוד קצרות"
  ]
}
```

---

## 🔄 3. התהליך המלא - מה קורה בכל הודעה?

### לפני יצירת התשובה:

```
1. טעינת זיכרון מתמשך
   ↓
2. יצירת snippet תמציתי (עד 500 תווים)
   ↓
3. טעינת זיכרון פעיל (ACTIVE_CONVERSATION)
   ↓
4. חיפוש RAG chunks (מחומרי הקורס)
   ↓
5. בניית פרומפט:
   - System prompt (אישיות טל בשן)
   - RAG chunks (חומרי הקורס)
   - זיכרון מתמשך (snippet)
   - זיכרון פעיל (סיכום השיחה)
   - הודעות אחרונות (20 הודעות)
   - שאלה נוכחית
   ↓
6. שליחה ל-LLM
   ↓
7. קבלת תשובה
```

### אחרי קבלת התשובה:

```
1. שמירת תשובת העוזר במסד הנתונים
   ↓
2. עדכון זיכרון פעיל:
   - איסוף כל ההודעות מהשיחה
   - יצירת סיכום חדש עם LLM
   - שמירה/עדכון במסד
   ↓
3. עדכון זיכרון מתמשך:
   - שליחת הזיכרון הנוכחי + הודעה + תשובה ל-LLM
   - LLM מחזיר JSON מעודכן
   - שמירה במסד
```

---

## 🎯 4. למה שני סוגי זיכרונות?

### זיכרון פעיל (ACTIVE_CONVERSATION):
- ✅ **מטרה**: שמירה על רצף בשיחה הנוכחית
- ✅ **תדירות**: מתעדכן בכל הודעה
- ✅ **תוכן**: סיכום של מה שנאמר בשיחה
- ✅ **חיים**: רק בזמן השיחה הפעילה

### זיכרון מתמשך (Long-term):
- ✅ **מטרה**: שמירה על עובדות והעדפות מתמשכות
- ✅ **תדירות**: מתעדכן אחרי כל הודעה (אם יש משהו חדש)
- ✅ **תוכן**: עובדות, העדפות, נושאים, פרופיל
- ✅ **חיים**: נשמר בין שיחות, גם אחרי 40+ הודעות

---

## 💡 5. איך זה עוזר?

### דוגמה 1: המשתמש שואל "מה זה מעגל התודעה?"
```
1. זיכרון פעיל: "המשתמש שאל קודם על תודעה ראקטיבית"
   → העוזר יכול להתייחס לשאלות הקודמות

2. זיכרון מתמשך: "המשתמש מעדיף הסברים קצרים"
   → העוזר יכול להתאים את אורך התשובה

3. RAG chunks: חומרי הקורס על מעגל התודעה
   → העוזר משתמש במידע המדויק מהקורס
```

### דוגמה 2: אחרי 50 הודעות
```
1. זיכרון פעיל: סיכום של כל 50 ההודעות (2-4 משפטים)
   → העוזר זוכר מה נדון בשיחה

2. זיכרון מתמשך: עובדות חשובות שנאספו לאורך כל השיחות
   → העוזר זוכר העדפות, נושאים, ופרטים אישיים

3. אין תלות באורך השיחה - הזיכרון תמיד נטען
```

---

## 🔧 6. ניהול גודל הזיכרון

### זיכרון פעיל:
- תמיד סיכום קצר (2-4 משפטים)
- מתעדכן בכל הודעה עם סיכום חדש

### זיכרון מתמשך:
- **Snippet**: רק החשוב ביותר נשלח לפרומפט (עד 500 תווים)
- **Cleanup**: פריטים ישנים/לא חשובים נמחקים
- **Summarization**: אם הזיכרון גדול מדי, LLM יוצר סיכום

---

## 📊 7. איפה הכל נשמר?

### במסד הנתונים:

1. **`user_memories`** - זיכרון פעיל
   - `summary`: הסיכום בעברית
   - `embedding`: וקטור 1536 מימדים
   - `memoryType`: `ACTIVE_CONVERSATION`

2. **`user_contexts`** - זיכרון מתמשך
   - `context`: JSON string עם כל הזיכרון

3. **`messages`** - כל ההודעות (Transcript)
   - נשמרות לצמיתות
   - משמשות ליצירת סיכומים

---

## 🎨 8. איך זה נראה בפרומפט?

```
System Prompt:
---
אתה טל בשן...

קונטקסט מחומרי הקורס:
[מקור 1] chunk_metzada.md: ...
[מקור 2] chunk_bor.md: ...

זיכרון מתמשך של המשתמש:
פרופיל: name: עומר, location: תל אביב
העדפות: מעדיף תשובות בעברית, אוהב דוגמאות קצרות
עובדות חשובות: המשתמש עובד כמפתח backend

זיכרון מהשיחה הפעילה (מה שנאמר קודם):
המשתמש שאל על תודעה ראקטיבית. הסברתי שהתודעה הריאקטיבית 
מתייחסת לתגובות אוטומטיות...

**חשוב:** 
- הזיכרון המתמשך מכיל עובדות, העדפות ונושאים מתמשכים
- הזיכרון מהשיחה הפעילה מכיל סיכום של מה שנאמר קודם בשיחה
- השתמש בשניהם כדי לשמור על רצף ועקביות
---

User Message:
מה זה מעגל התודעה?
```

---

## ✅ סיכום

המערכת משתמשת בשני מנגנוני זיכרון:

1. **זיכרון פעיל** - מתעדכן בכל הודעה, שומר על רצף השיחה
2. **זיכרון מתמשך** - מתעדכן עם LLM, שומר עובדות והעדפות

שניהם נטענים לפני כל תשובה ומתעדכנים אחרי כל תשובה, כך שהעוזר תמיד זוכר את המשתמש ואת מה שנאמר.

